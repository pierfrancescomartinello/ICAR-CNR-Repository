{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pyngrok\n",
        "!ngrok config add-authtoken 2drfhhKc0daEhPzXnYUdG4JVkWK_6uJbeyQbjiwEc5NdNamMn\n",
        "!pip install -q diffusers\n",
        "!git clone https://github.com/openai/shap-e.git; cd shap-e/; pip -q install -e ."
      ],
      "metadata": {
        "id": "N1BQtP-G7iKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b1c47d-3e6f-4c57-93c8-83153b88e7a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "fatal: destination path 'shap-e' already exists and is not an empty directory.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "4ZB_zrsiwZNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
        "from diffusers.utils import export_to_gif\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#\n",
        "# xm = load_model('transmitter', device=device)\n",
        "# model = load_model('text300M', device=device)\n",
        "# diffusion = diffusion_from_config(load_config('diffusion'))"
      ],
      "metadata": {
        "id": "qHegMAG_8_HX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "import time\n",
        "from urllib import parse\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "\n",
        "from flask import Flask, request, jsonify, Response\n",
        "from pyngrok import ngrok, conf"
      ],
      "metadata": {
        "id": "WHPUGBYYyCtx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route(\"/auth\", methods=[\"POST\"])\n",
        "def authorization():\n",
        "    # Authorize a new client. Accessible using <url>/auth?cli_id=<id>\n",
        "    cli_id = request.args[\"cli_id\"]\n",
        "    if cli_id in clients:\n",
        "        # Already authorized\n",
        "        return '', 401 # Unauthorized\n",
        "    else:\n",
        "        clients[cli_id] = time.time()\n",
        "        return '', 200 # OK\n",
        "\n",
        "@app.route(\"/query\", methods = [\"GET\"])\n",
        "def pictures_exchange():\n",
        "    cli_id = request.args[\"cli_id\"]\n",
        "    if cli_id not in clients:\n",
        "        return '', 401 # Unauthorized\n",
        "    query = parse.unquote(request.args[\"query\"])\n",
        "    tentatives = int(parse.unquote(request.args[\"tentatives\"]))\n",
        "    return \"\", 200\n",
        "    # Ask for query\n",
        "    models = query_inference(query, tentatives)\n",
        "    cache = cache_update(cache, query, cli_id, models, 60*10)\n",
        "\n",
        "    return \"\", 200\n",
        "\n",
        "    files = dict()\n",
        "    for i, model in enumerate(models):\n",
        "        filename = f\"output_{hash(cli_id)}_{hash(query)}_{i}.gif\"\n",
        "        # If it appears there is already\n",
        "        if os.path.exists(filename): os.remove(filename)\n",
        "\n",
        "        export_to_gif((model), filename)\n",
        "        files[f\"gif_{i}.gif\"] = open(filename, \"rb\")\n",
        "\n",
        "    return jsonify(data = \"files\", status = 200, mimetype = \"image/gif\")\n",
        "\n",
        "def getting_the_model():\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "def query_inference(prompt:str, tentatives:int):\n",
        "    images = sample_latents(\n",
        "        batch_size=tentatives,\n",
        "        model=model,\n",
        "        diffusion=diffusion,\n",
        "        guidance_scale=guidance_scale,\n",
        "        model_kwargs=dict(texts=[prompt] * tentatives),\n",
        "        progress=True,\n",
        "        clip_denoised=True,\n",
        "        use_fp16=True,\n",
        "        use_karras=True,\n",
        "        karras_steps=64,\n",
        "        sigma_min=1e-3,\n",
        "        sigma_max=160,\n",
        "        s_churn=0,\n",
        "    )\n",
        "    return images\n",
        "\n",
        "\n",
        "def cache_update(cache, query, cli_id, models, time):\n",
        "    # If more that <time> has passed, remove a cached element\n",
        "    temp_cache = []\n",
        "    for i, element in enumerate(cache):\n",
        "        if time.time() - element.time() < time:\n",
        "            temp_cache.append(element)\n",
        "\n",
        "    temp_cache.append(Created_Object_Cache(models, cli_id, query))\n",
        "    return temp_cache"
      ],
      "metadata": {
        "id": "H5M5Uzq4x_60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXiOs3_YCGnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6845cfb3-0d0b-4df6-99ae-1e6c71ee3c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "https://e410-34-105-92-156.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        }
      ],
      "source": [
        "def getting_the_model():\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "def query_inference(prompt:str, tentatives:int):\n",
        "    images = sample_latents(\n",
        "        batch_size=tentatives,\n",
        "        model=model,\n",
        "        diffusion=diffusion,\n",
        "        guidance_scale=guidance_scale,\n",
        "        model_kwargs=dict(texts=[prompt] * tentatives),\n",
        "        progress=True,\n",
        "        clip_denoised=True,\n",
        "        use_fp16=True,\n",
        "        use_karras=True,\n",
        "        karras_steps=64,\n",
        "        sigma_min=1e-3,\n",
        "        sigma_max=160,\n",
        "        s_churn=0,\n",
        "    )\n",
        "    return images\n",
        "\n",
        "\n",
        "def cache_update(cache, query, cli_id, models, time):\n",
        "    # If more that <time> has passed, remove a cached element\n",
        "    temp_cache = []\n",
        "    for i, element in enumerate(cache):\n",
        "        if time.time() - element.time() < time:\n",
        "            temp_cache.append(element)\n",
        "\n",
        "    temp_cache.append(Created_Object_Cache(models, cli_id, query))\n",
        "    return temp_cache\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    class Created_Object_Cache():\n",
        "        def __init__(self, objects, requester, query):\n",
        "            self.object = objects\n",
        "            (self.requester ,self.query) = (requester, query)\n",
        "            self.time = time.time()\n",
        "\n",
        "\n",
        "    # Setup stuff for shap-e\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(torch.cuda.is_available())\n",
        "    xm = load_model('transmitter', device=device)\n",
        "    model = load_model('text300M', device=device)\n",
        "    diffusion = diffusion_from_config(load_config('diffusion'))\n",
        "\n",
        "    guidance_scale = 15.0\n",
        "\n",
        "    # Setup for flask\n",
        "    app = Flask(__name__)\n",
        "    port = \"5000\"\n",
        "\n",
        "    conf.get_default().authtoken = \"2drfhhKc0daEhPzXnYUdG4JVkWK_6uJbeyQbjiwEc5NdNamMn\"\n",
        "\n",
        "    # Open a ngrok tunnel to the HTTP server\n",
        "    public_url = ngrok.connect(port).public_url\n",
        "    print(f\"{public_url}\")\n",
        "\n",
        "    # Update any base URLs to use the public ngrok URL\n",
        "    app.config[\"BASE_URL\"] = public_url\n",
        "    clients = dict()\n",
        "    cache = list()\n",
        "\n",
        "    #app.run(debug = False, threaded=False, use_reloader = False)\n",
        "\n",
        "    # Use Threads?\n",
        "    threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()\n",
        "\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return \"\", 200\n",
        "\n",
        "@app.route(\"/auth\", methods=[\"POST\"])\n",
        "def authorization():\n",
        "    # Authorize a new client. Accessible using <url>/auth?cli_id=<id>\n",
        "    cli_id = request.args[\"cli_id\"]\n",
        "    if cli_id in clients:\n",
        "        # Already authorized\n",
        "        return '', 401 # Unauthorized\n",
        "    else:\n",
        "        clients[cli_id] = time.time()\n",
        "        return '', 200 # OK\n",
        "\n",
        "@app.route(\"/query\", methods = [\"GET\"])\n",
        "def pictures_exchange():\n",
        "    cli_id = request.args[\"cli_id\"]\n",
        "    if cli_id not in clients:\n",
        "        return '', 401 # Unauthorized\n",
        "    query = parse.unquote(request.args[\"query\"])\n",
        "    tentatives = int(parse.unquote(request.args[\"tentatives\"]))\n",
        "    # Ask for query\n",
        "    models = query_inference(query, tentatives)\n",
        "    cache = cache_update(cache, query, cli_id, models, 60*10)\n",
        "\n",
        "    return Response(response=\"HELLO PART 2\", status=200)\n",
        "\n",
        "    files = dict()\n",
        "    for i, model in enumerate(models):\n",
        "        filename = f\"output_{hash(cli_id)}_{hash(query)}_{i}.gif\"\n",
        "        # If it appears there is already\n",
        "        if os.path.exists(filename): os.remove(filename)\n",
        "\n",
        "        export_to_gif((model), filename)\n",
        "        files[f\"gif_{i}.gif\"] = open(filename, \"rb\")\n",
        "\n",
        "    return jsonify(data = \"files\", status = 200, mimetype = \"image/gif\")\n",
        "\n"
      ]
    }
  ]
}